# -*- coding: utf-8 -*-
"""taxi Fare Predictions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15zQE3ghiFsVi8kyFUfmV-ykXFPZEbdYu
"""

!wget 'https://storage.googleapis.com/kaggle-competitions-data/kaggle-v2/10170/61318/compressed/train.csv.zip?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1636127029&Signature=By%2BROTgOTP6q0h1A6i8XZV9UgMfPQCEvbEfNuF8mhTKqLFjLsr0q3DpVbl99kWcNqj%2B4%2BemzxrdDzCwEfF6O%2FdYG5sfYorlR%2FjEpO01RL8C1nn3F%2BeZJQDdyImJHqUgYGPWHAGprKUVDyS1Ui4eUTfEjfOC6dX7LYfQVRkBdUD82z%2FO96lZHK9MIbrstlYK%2Ff3dKVQFZsSQXrvoluhde82ga%2BtxPydyIfvdpT6jtschMylynl6zYrGHPzYqgGFDZUJtEqgOLgj%2FcBKKANqTKMgojoK4NT3Tyu%2BLuyzEkEJY1T5LDg4KcJzBBORu3c2Y3VqlnDzVr0cPS%2F1peksaVvA%3D%3D&response-content-disposition=attachment%3B+filename%3Dtrain.csv.zip'

!wget 'https://storage.googleapis.com/kagglesdsdata/competitions/10170/61318/test.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1636127071&Signature=Q89tG9Gwj27qbQmBpq3eQv2FsLKuwAJkzf23RKqaYm%2FOhoA7%2BES3i5CMo90mEMxdYPUGj%2FZ9ArWBg5168%2BUv16FvX0HCZsGaIo9Xzm4UYURR505KFybBblPEPAm%2F1ZFzGfAvORWCI%2BVKeZNXhYppWSdk%2FccsrHX472OuFDXwhqbT8Ww4mcgvs64Zhm262o8QmSbT2bI5KVv636mBAJnvBNCsczG368AzkgQMn1jrqMXxr3u3hLxTpT8meJH%2Bj%2FUlmZB6b5561l4aIe5qLhdQPMx1E%2Bp50rdMy%2BUbK3jhqQP8xBupeJFYdyyo%2BKVwuomuVTRBANOHKjzfoNUD8vGu%2Fw%3D%3D&response-content-disposition=attachment%3B+filename%3Dtest.csv'

!wget 'https://storage.googleapis.com/kagglesdsdata/competitions/10170/61318/sample_submission.csv?GoogleAccessId=web-data@kaggle-161607.iam.gserviceaccount.com&Expires=1636127114&Signature=gJCJUA3LfZHeE5pduH3%2BLIinw5VnEfTZEr1kqze3qk01RSrtWr5NvLaHVf%2FbH%2BIefCSVWeJa7D5bqNLv6XMHjQvO2cYO8Nga1%2BS78xn0K0hDtcYX6JR4EaOts6YhrPuNRhc3dx4IQ0%2BayBIu28%2F3orw51FxALKz7McBctSidClIUXqmjVnidDJpiYY129LN02mQbnVhBBMaDTMB6NLTrjX4B4%2FAcF6pfRs5cjsO4kEtb6xLUum3DSJlIqdcB6q1vhl0tPHxds8yfxM0akZ%2BBt1jMbL8JvDNMH1Uyx1FkHtObOyPSOO9tFPGoOAVMhjBh2iJ9qEndYOdy8VUMbXDB9w%3D%3D&response-content-disposition=attachment%3B+filename%3Dsample_submission.csv'

import zipfile

with zipfile.ZipFile('train.csv.zip' , 'r') as zip_ref : 
  zip_ref.extractall('train')

import numpy as np
import pandas as pd
import sklearn
import seaborn as sns
import matplotlib.pyplot as plt
import os
print(os.listdir('../content/'))

sample = pd.read_csv('../content/sample_submission.csv')

train = pd.read_csv('../content/train/train.csv' , nrows = 1000000)

test = pd.read_csv('../content/test.csv')

train.shape

test.shape

train.head()

train.describe()

#check for missing values in train data

train.isnull().sum().sort_values(ascending = False)

#check for missing values in test data

test.isnull().sum().sort_values(ascending = False)

#drop the missing values
train.dropna(axis = 0 ,inplace =True)

train.shape

#check the target column
train['fare_amount'].describe()

from collections import Counter
Counter(train['fare_amount']<0)

#38 fields have negative fare_amount values

train = train.drop(train[train['fare_amount']<0].index , axis = 0)
train.shape

train['fare_amount'].describe()

train['fare_amount'].sort_values(ascending = False)

#check passenger_count variable 

train['passenger_count'].describe()

#max is 288 passenger

train[train['passenger_count']>6]

train = train.drop(train[train['passenger_count']>6].index , axis = 0)

train['passenger_count'].describe()

train['pickup_latitude'].describe()

"""Quick Googling gave me this info

Latitudes range from -90 to 90.

Longitudes range from -180 to 18


"""

train[train['pickup_latitude']< -90]

train[train['pickup_latitude']>90]

#we need to drop these outliers
train = train.drop(train[train['pickup_latitude']<-90].index , axis =0 )
train = train.drop(train[train['pickup_latitude']>90].index , axis =0 )

#12 rows dropped
train.shape

train['pickup_longitude'].describe()

train[train['pickup_longitude']<-180]

train[train['pickup_longitude']>180]

train = train.drop(train[train['pickup_longitude']<-180].index , axis =0 )
train = train.drop(train[train['pickup_longitude']>180].index , axis =0 )

#11 rows dropped
train.shape

train.dtypes

train = train.drop(train[train['dropoff_latitude']<-90].index , axis = 0)
train = train.drop(train[train['dropoff_latitude']>90].index , axis = 0)

#key and pickup_datetime ssem to be datetime columns which are in object format.Let's convert them to datetime

train['key'] = pd.to_datetime(train['key'])

train['pickup_datetime'] = pd.to_datetime(train['pickup_datetime'])

#convert for test data
test['key'] = pd.to_datetime(test['key'])

test['pickup_datetime'] = pd.to_datetime(test['pickup_datetime'])

train.dtypes

train.head()

test.head()

#new field 'distance' to fetch the distance between the pickup and the drop
def haversine_distance(lat1, long1, lat2, long2):
    data = [train, test]
    for i in data:
        R = 6371  #radius of earth in kilometers
        #R = 3959 #radius of earth in miles
        phi1 = np.radians(i[lat1])
        phi2 = np.radians(i[lat2])
    
        delta_phi = np.radians(i[lat2]-i[lat1])
        delta_lambda = np.radians(i[long2]-i[long1])
    
        #a = sin²((φB - φA)/2) + cos φA . cos φB . sin²((λB - λA)/2)
        a = np.sin(delta_phi / 2.0) ** 2 + np.cos(phi1) * np.cos(phi2) * np.sin(delta_lambda / 2.0) ** 2
    
        #c = 2 * atan2( √a, √(1−a) )
        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))
    
        #d = R*c
        d = (R * c) #in kilometers
        i['H_Distance'] = d
    return d
haversine_distance('pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude')

train['H_Distance'].head(10)

test['H_Distance'].head(10)

train.head()

data = [train , test]
for i in data : 
  i['Year'] = i['pickup_datetime'].dt.year
  i['Month'] = i['pickup_datetime'].dt.month
  i['Date'] = i['pickup_datetime'].dt.day
  i['Day of Week'] = i['pickup_datetime'].dt.dayofweek
  i['Hour'] = i['pickup_datetime'].dt.hour

train.head(-5)

test.head()

plt.figure(figsize = (15,7))
plt.hist(train['passenger_count'] , bins = 15)
plt.xlabel('No. of passengers')
plt.ylabel('Frequency')

plt.figure(figsize =(15,7))
plt.scatter(x = train['passenger_count'] , y = train['fare_amount'])
plt.xlabel('No . of Passengers')
plt.ylabel('Fare')

#The fares throught the month mostly seem uniform, with the maximum fare received on the 12th
plt.figure(figsize = (15 , 7))
plt.scatter(x = train['Date'] , y = train['fare_amount'] , s = 1.5)
plt.xlabel('Date')
plt.ylabel('Fare')

plt.figure(figsize = (15 , 7 ))
plt.hist(train['Hour'] , bins = 100)
plt.xlabel('Hour')
plt.ylabel('Frequency')

plt.figure(figsize = (15 , 7))
plt.scatter(x = train['Hour'] , y = train['fare_amount'] , s=1.5)
plt.xlabel('Hour')
plt.ylabel('Fare')

plt.figure(figsize=(15,7))
plt.hist(train['Day of Week'], bins=100)
plt.xlabel('Day of Week')
plt.ylabel('Frequency')

plt.figure(figsize=(15,7))
plt.scatter(x=train['Day of Week'], y=train['fare_amount'], s=1.5)
plt.xlabel('Day of Week')
plt.ylabel('Fare')

train.sort_values(['H_Distance','fare_amount'], ascending=False)

len(train)

bins_0 = train.loc[(train['H_Distance'] == 0) , ['H_Distance']]
bins_1 = train.loc[(train['H_Distance'] >0) & (train['H_Distance']<=10) , ['H_Distance']]
bins_2 = train.loc[(train['H_Distance']>10) & (train['H_Distance']<=50) , ['H_Distance']]
bins_3 = train.loc[(train['H_Distance']>50) & (train['H_Distance']<=100) , ['H_Distance']]
bins_4 = train.loc[(train['H_Distance']>100) & (train['H_Distance']<=200) , ['H_Distance']]
bins_5 = train.loc[(train['H_Distance']>200) & (train['H_Distance']<=300) , ['H_Distance']]
bins_6 = train.loc[(train['H_Distance']>300), ['H_Distance']]
bins_0['bins'] = '0'
bins_1['bins'] = '0-10'
bins_2['bins'] = '11-50'
bins_3['bins'] = '51-100'
bins_4['bins'] = '100-200'
bins_5['bins'] = '201-300'
bins_6['bins'] = '>300'

dist_bins =pd.concat([bins_0,bins_1,bins_2,bins_3,bins_4,bins_5,bins_6])
dist_bins.columns

plt.figure(figsize = (15,7))
plt.hist(dist_bins['bins'], bins =75)
plt.xlabel('bins')
plt.ylabel('Frequency')

Counter(dist_bins['bins'])

#pickup latitude and logitude = 0 

train.loc[((train['pickup_latitude'] == 0) & (train['pickup_longitude'] == 0 )) &((train['dropoff_latitude'] != 0) | (train['dropoff_longitude']!=0)) &(train['fare_amount']==0)]

train = train.drop(train.loc[((train['pickup_latitude'] == 0) & (train['pickup_longitude'] == 0 )) &((train['dropoff_latitude'] != 0) | (train['dropoff_longitude']!=0)) &(train['fare_amount']==0)].index , axis = 0)

#1 row dropped
train.shape

test.loc[((test['pickup_latitude']==0)&(test['pickup_longitude']==0))&((test['dropoff_latitude']!=0)|(test['dropoff_longitude']!=0))]

#dropoff latitude and logitude = 0
train.loc[((train['pickup_latitude']!=0) & (train['pickup_longitude']!=0))&((train['dropoff_latitude']==0) & (train['dropoff_longitude']==0)) & (train['fare_amount']==0)]

train = train.drop(train.loc[((train['pickup_latitude']!=0) & (train['pickup_longitude']!=0))&((train['dropoff_latitude']==0) & (train['dropoff_longitude']==0)) & (train['fare_amount']==0)].index, axis=0)

train.shape

#Checking test data
#Again no records! AWESOME!
test.loc[((test['pickup_latitude']!=0) & (test['pickup_longitude']!=0))&((test['dropoff_latitude']==0) & (test['dropoff_longitude']==0))]

"""check the H_Distance fields with are greater thn 200 kms"""

high_distance = train.loc[(train['H_Distance']>200) &(train['fare_amount']!=0)]

high_distance

high_distance.shape

high_distance['H_Distance'] = high_distance.apply(
    lambda row: (row['fare_amount'] - 2.50)/1.7,
    axis=1
)

high_distance.shape

train.update(high_distance)

train[train['H_Distance']==0]

#fare and Distance are both 0
train[(train['H_Distance']==0) & (train['fare_amount']==0)]

train = train.drop(train[(train['H_Distance']==0) & (train['fare_amount']==0)].index ,axis = 0)

bad_data = train.loc[((train['Hour']>=6) &(train['Hour']<=20)) &((train['Day of Week']>=1) & (train['Day of Week']<=5)) & (train['H_Distance']==0) &(train['fare_amount']<2.5)]

train=train.drop(bad_data.index, axis=0)

train.shape

#Between 8PM and 6AM
bad_data = train.drop(train[((train['Hour']<6) | (train['Hour']>20)) & ((train['Day of Week']>=1) & (train['Day of Week']<=5)) &((train['H_Distance']==0)&(train['fare_amount']<3.0))].index , axis = 0)

train.shape

train = train.drop(train[((train['Day of Week']==0) | (train['Day of Week']==6)) & (train['H_Distance']==0) & (train['fare_amount'] < 3.0)].index , axis = 0)

train.shape

train = train.drop(train[(train['H_Distance']!=0) & (train['fare_amount']==0) &(train['H_Distance']>0.001)].index, axis = 0)

train.shape

#problem
bad_data = train.loc[(train['H_Distance']==0)&(train['fare_amount']!=0)]

bad_data.shape

bad_data.loc[((bad_data['H_Distance']==0) & (bad_data['fare_amount']<=3.0))].shape

bad_data.loc[(bad_data['H_Distance']==0) & (bad_data['fare_amount']>3.0)].shape

bad_data['H_Distance'] = bad_data.apply(
    lambda row : ((row['fare_amount'] -2.5)/1.56),axis = 1
)

train.update(bad_data)

train.shape

"""Data Cleaning is done """

train.head()

train.drop(columns = ['key' , 'pickup_datetime'] , axis=1 , inplace = True)
test.drop(columns = ['key' , 'pickup_datetime'] , axis = 1 , inplace = True)

x_train = train.drop(columns=['fare_amount'])

y_train = train['fare_amount']

x_test = test

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor()

rf.fit(x_train , y_train)

y_test = rf.predict(x_test)

sample['fare_amount'] = y_test

sample.to_csv('submission_1.csv' , index = False)

